{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5OncETA8hzP_",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5OncETA8hzP_",
    "outputId": "c86b4f13-4d38-445a-f474-1f631bc50b49"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.4.1'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')\n",
    "import tensorflow\n",
    "tensorflow.__version__\n",
    "# !pip install tensorflow==2.4.1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d714c605",
   "metadata": {
    "id": "d714c605"
   },
   "outputs": [],
   "source": [
    "def warn(*args, **kwargs):\n",
    "    pass\n",
    "import warnings\n",
    "warnings.warn = warn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9e939a62",
   "metadata": {
    "id": "9e939a62"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from time import time\n",
    "import cv2\n",
    "import tensorflow.keras as keras\n",
    "keras.__version__\n",
    "import tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1_5nCqLZoNqt",
   "metadata": {
    "id": "1_5nCqLZoNqt"
   },
   "outputs": [],
   "source": [
    "keras = tensorflow.compat.v1.keras\n",
    "Sequence = tensorflow.keras.utils.Sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e9658b0e",
   "metadata": {
    "id": "e9658b0e"
   },
   "outputs": [],
   "source": [
    "# import keras\n",
    "# from tensorflow.keras.utils import Sequence\n",
    "from tensorflow.keras import utils \n",
    "\n",
    "class DataGenerator(Sequence):\n",
    "    \"\"\"Data Generator inherited from keras.utils.Sequence\n",
    "    Args: \n",
    "        directory: the path of data set, and each sub-folder will be assigned to one class\n",
    "        batch_size: the number of data points in each batch\n",
    "        shuffle: whether to shuffle the data per epoch\n",
    "    Note:\n",
    "        If you want to load file with other data format, please fix the method of \"load_data\" as you want\n",
    "    \"\"\"\n",
    "    def __init__(self, directory, batch_size=1, shuffle=True, data_augmentation=True):\n",
    "        # Initialize the params\n",
    "        self.batch_size = batch_size\n",
    "        self.directory = directory\n",
    "        self.shuffle = shuffle\n",
    "        self.data_aug = data_augmentation\n",
    "        # Load all the save_path of files, and create a dictionary that save the pair of \"data:label\"\n",
    "        self.X_path, self.Y_dict = self.search_data() \n",
    "        # Print basic statistics information\n",
    "        self.print_stats()\n",
    "        return None\n",
    "    def search_data(self):\n",
    "        X_path = []\n",
    "        Y_dict = {}\n",
    "        # list all kinds of sub-folders\n",
    "        self.dirs = sorted(os.listdir(self.directory))\n",
    "        one_hots = utils.to_categorical(range(len(self.dirs)))\n",
    "        for i,folder in enumerate(self.dirs):\n",
    "            folder_path = os.path.join(self.directory,folder)\n",
    "            for file in os.listdir(folder_path):\n",
    "                file_path = os.path.join(folder_path,file)\n",
    "                # append the each file path, and keep its label  \n",
    "                X_path.append(file_path)\n",
    "                Y_dict[file_path] = one_hots[i]\n",
    "        return X_path, Y_dict\n",
    "    \n",
    "    def print_stats(self):\n",
    "        # calculate basic information\n",
    "        self.n_files = len(self.X_path)\n",
    "        self.n_classes = len(self.dirs)\n",
    "        self.indexes = np.arange(len(self.X_path))\n",
    "        np.random.shuffle(self.indexes)\n",
    "        # Output states\n",
    "        print(\"Found {} files belonging to {} classes.\".format(self.n_files,self.n_classes))\n",
    "        for i,label in enumerate(self.dirs):\n",
    "            print('%10s : '%(label),i)\n",
    "        return None\n",
    "    def __len__(self):\n",
    "        # calculate the iterations of each epoch\n",
    "        steps_per_epoch = np.ceil(len(self.X_path) / float(self.batch_size))\n",
    "        return int(steps_per_epoch)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"Get the data of each batch\n",
    "        \"\"\"\n",
    "        # get the indexs of each batch\n",
    "        batch_indexs = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
    "        # using batch_indexs to get path of current batch\n",
    "        batch_path = [self.X_path[k] for k in batch_indexs]\n",
    "        # get batch data\n",
    "        batch_x, batch_y = self.data_generation(batch_path)\n",
    "        return batch_x, batch_y\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        # shuffle the data at each end of epoch\n",
    "        if self.shuffle == True:\n",
    "            np.random.shuffle(self.indexes)\n",
    "\n",
    "    def data_generation(self, batch_path):\n",
    "        # load data into memory, you can change the np.load to any method you want\n",
    "        batch_x = [self.load_data(x) for x in batch_path]\n",
    "        batch_y = [self.Y_dict[x] for x in batch_path]\n",
    "        # transfer the data format and take one-hot coding for labels\n",
    "        batch_x = np.array(batch_x)\n",
    "        batch_y = np.array(batch_y)\n",
    "        return batch_x, batch_y\n",
    "    \n",
    "    def normalize(self, data):\n",
    "        mean = np.mean(data)\n",
    "        std = np.std(data)\n",
    "        return (data-mean) / std\n",
    "    \n",
    "    def random_flip(self, video, prob):\n",
    "        s = np.random.rand()\n",
    "        if s < prob:\n",
    "            video = np.flip(m=video, axis=2)\n",
    "        return video    \n",
    "    \n",
    "    def uniform_sampling(self, video, target_frames=64):\n",
    "        # get total frames of input video and calculate sampling interval \n",
    "        len_frames = int(len(video))\n",
    "        interval = int(np.ceil(len_frames/target_frames))\n",
    "        # init empty list for sampled video and \n",
    "        sampled_video = []\n",
    "        for i in range(0,len_frames,interval):\n",
    "            sampled_video.append(video[i])     \n",
    "        # calculate numer of padded frames and fix it \n",
    "        num_pad = target_frames - len(sampled_video)\n",
    "        padding = []\n",
    "        if num_pad>0:\n",
    "            for i in range(-num_pad,0):\n",
    "                try: \n",
    "                    padding.append(video[i])\n",
    "                except:\n",
    "                    padding.append(video[0])\n",
    "            sampled_video += padding     \n",
    "        # get sampled video\n",
    "        return np.array(sampled_video, dtype=np.float32)\n",
    "    \n",
    "    def random_clip(self, video, target_frames=64):\n",
    "        start_point = np.random.randint(len(video)-target_frames)\n",
    "        return video[start_point:start_point+target_frames]\n",
    "    \n",
    "    def dynamic_crop(self, video):\n",
    "        # extract layer of optical flow from video\n",
    "        opt_flows = video[...,3]\n",
    "        # sum of optical flow magnitude of individual frame\n",
    "        magnitude = np.sum(opt_flows, axis=0)\n",
    "        # filter slight noise by threshold \n",
    "        thresh = np.mean(magnitude)\n",
    "        magnitude[magnitude<thresh] = 0\n",
    "        # calculate center of gravity of magnitude map and adding 0.001 to avoid empty value\n",
    "        x_pdf = np.sum(magnitude, axis=1) + 0.001\n",
    "        y_pdf = np.sum(magnitude, axis=0) + 0.001\n",
    "        # normalize PDF of x and y so that the sum of probs = 1\n",
    "        x_pdf /= np.sum(x_pdf)\n",
    "        y_pdf /= np.sum(y_pdf)\n",
    "        # randomly choose some candidates for x and y \n",
    "        x_points = np.random.choice(a=np.arange(224), size=10, replace=True, p=x_pdf)\n",
    "        y_points = np.random.choice(a=np.arange(224), size=10, replace=True, p=y_pdf)\n",
    "        # get the mean of x and y coordinates for better robustness\n",
    "        x = int(np.mean(x_points))\n",
    "        y = int(np.mean(y_points))\n",
    "        # avoid to beyond boundaries of array\n",
    "        x = max(56,min(x,167))\n",
    "        y = max(56,min(y,167))\n",
    "        # get cropped video \n",
    "        return video[:,x-56:x+56,y-56:y+56,:] \n",
    "    \n",
    "    def color_jitter(self,video):\n",
    "        # range of s-component: 0-1\n",
    "        # range of v component: 0-255\n",
    "        s_jitter = np.random.uniform(-0.2,0.2)\n",
    "        v_jitter = np.random.uniform(-30,30)\n",
    "        for i in range(len(video)):\n",
    "            hsv = cv2.cvtColor(video[i], cv2.COLOR_RGB2HSV)\n",
    "            s = hsv[...,1] + s_jitter\n",
    "            v = hsv[...,2] + v_jitter\n",
    "            s[s<0] = 0\n",
    "            s[s>1] = 1\n",
    "            v[v<0] = 0\n",
    "            v[v>255] = 255\n",
    "            hsv[...,1] = s\n",
    "            hsv[...,2] = v\n",
    "            video[i] = cv2.cvtColor(hsv, cv2.COLOR_HSV2RGB)\n",
    "        return video\n",
    "        \n",
    "    def load_data(self, path):\n",
    "        # load the processed .npy files which have 5 channels (1-3 for RGB, 4-5 for optical flows)\n",
    "        data = np.load(path, mmap_mode='r')\n",
    "        data = np.float32(data)\n",
    "        # sampling 64 frames uniformly from the entire video\n",
    "        data = self.uniform_sampling(video=data, target_frames=64)\n",
    "        # whether to utilize the data augmentation\n",
    "        if  self.data_aug:\n",
    "            data[...,:3] = self.color_jitter(data[...,:3])\n",
    "            data = self.random_flip(data, prob=0.5)\n",
    "        # normalize rgb images and optical flows, respectively\n",
    "        data[...,:3] = self.normalize(data[...,:3])\n",
    "        data[...,3:] = self.normalize(data[...,3:])\n",
    "        return data\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "95d3b831",
   "metadata": {
    "id": "95d3b831"
   },
   "outputs": [],
   "source": [
    "from tensorflow.python.keras.models  import Sequential, Input, Model\n",
    "from tensorflow.keras.layers import Dense, Flatten, Conv3D, MaxPooling3D, Dropout, BatchNormalization, Activation, LeakyReLU, Lambda, Add, Multiply\n",
    "from tensorflow.keras.regularizers import l2\n",
    "import tensorflow.keras.layers\n",
    "# import keras.optimizers.Adam\n",
    "# from keras.layers.core import Lambda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "73164bbc",
   "metadata": {
    "id": "73164bbc"
   },
   "outputs": [],
   "source": [
    "# extract the rgb images \n",
    "def get_rgb(input_x):\n",
    "    rgb = input_x[...,:3]\n",
    "    return rgb\n",
    "\n",
    "# extract the optical flows\n",
    "def get_opt(input_x):\n",
    "    opt= input_x[...,3:5]\n",
    "    return opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8c3f1b36",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8c3f1b36",
    "outputId": "d89478d5-8540-43b8-88a9-a8677ca70721"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 64, 224, 224 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda (Lambda)                 (None, 64, 224, 224, 0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, 64, 224, 224, 0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv3d (Conv3D)                 (None, 64, 224, 224, 448         lambda[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_8 (Conv3D)               (None, 64, 224, 224, 304         lambda_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_1 (Conv3D)               (None, 64, 224, 224, 784         conv3d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_9 (Conv3D)               (None, 64, 224, 224, 784         conv3d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling3d (MaxPooling3D)    (None, 64, 112, 112, 0           conv3d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling3d_4 (MaxPooling3D)  (None, 64, 112, 112, 0           conv3d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_2 (Conv3D)               (None, 64, 112, 112, 2320        max_pooling3d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_10 (Conv3D)              (None, 64, 112, 112, 2320        max_pooling3d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_3 (Conv3D)               (None, 64, 112, 112, 784         conv3d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_11 (Conv3D)              (None, 64, 112, 112, 784         conv3d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling3d_1 (MaxPooling3D)  (None, 64, 56, 56, 1 0           conv3d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling3d_5 (MaxPooling3D)  (None, 64, 56, 56, 1 0           conv3d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_4 (Conv3D)               (None, 64, 56, 56, 3 4640        max_pooling3d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_12 (Conv3D)              (None, 64, 56, 56, 3 4640        max_pooling3d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_5 (Conv3D)               (None, 64, 56, 56, 3 3104        conv3d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_13 (Conv3D)              (None, 64, 56, 56, 3 3104        conv3d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling3d_2 (MaxPooling3D)  (None, 64, 28, 28, 3 0           conv3d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling3d_6 (MaxPooling3D)  (None, 64, 28, 28, 3 0           conv3d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_6 (Conv3D)               (None, 64, 28, 28, 3 9248        max_pooling3d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_14 (Conv3D)              (None, 64, 28, 28, 3 9248        max_pooling3d_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_7 (Conv3D)               (None, 64, 28, 28, 3 3104        conv3d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_15 (Conv3D)              (None, 64, 28, 28, 3 3104        conv3d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling3d_3 (MaxPooling3D)  (None, 64, 14, 14, 3 0           conv3d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling3d_7 (MaxPooling3D)  (None, 64, 14, 14, 3 0           conv3d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "multiply (Multiply)             (None, 64, 14, 14, 3 0           max_pooling3d_3[0][0]            \n",
      "                                                                 max_pooling3d_7[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling3d_8 (MaxPooling3D)  (None, 8, 14, 14, 32 0           multiply[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_16 (Conv3D)              (None, 8, 14, 14, 64 18496       max_pooling3d_8[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_17 (Conv3D)              (None, 8, 14, 14, 64 12352       conv3d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling3d_9 (MaxPooling3D)  (None, 4, 7, 7, 64)  0           conv3d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_18 (Conv3D)              (None, 4, 7, 7, 64)  36928       max_pooling3d_9[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_19 (Conv3D)              (None, 4, 7, 7, 64)  12352       conv3d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling3d_10 (MaxPooling3D) (None, 2, 3, 3, 64)  0           conv3d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_20 (Conv3D)              (None, 2, 3, 3, 128) 73856       max_pooling3d_10[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_21 (Conv3D)              (None, 2, 3, 3, 128) 49280       conv3d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling3d_11 (MaxPooling3D) (None, 1, 1, 1, 128) 0           conv3d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 1, 1, 1, 128) 16512       max_pooling3d_11[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 1, 1, 1, 128) 0           dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1, 1, 1, 32)  4128        dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 1, 1, 1, 2)   66          dense_1[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 272,690\n",
      "Trainable params: 272,690\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import  Lambda\n",
    "\n",
    "inputs = Input(shape=(64,224,224,5))\n",
    "\n",
    "rgb = Lambda(get_rgb,output_shape=None)(inputs)\n",
    "opt = Lambda(get_opt,output_shape=None)(inputs)\n",
    "\n",
    "##################################################### RGB channel\n",
    "rgb = Conv3D(\n",
    "    16, kernel_size=(1,3,3), strides=(1,1,1), kernel_initializer='he_normal', activation='relu', padding='same')(rgb)\n",
    "rgb = Conv3D(\n",
    "    16, kernel_size=(3,1,1), strides=(1,1,1), kernel_initializer='he_normal', activation='relu', padding='same')(rgb)\n",
    "rgb = MaxPooling3D(pool_size=(1,2,2))(rgb)\n",
    "\n",
    "rgb = Conv3D(\n",
    "    16, kernel_size=(1,3,3), strides=(1,1,1), kernel_initializer='he_normal', activation='relu', padding='same')(rgb)\n",
    "rgb = Conv3D(\n",
    "    16, kernel_size=(3,1,1), strides=(1,1,1), kernel_initializer='he_normal', activation='relu', padding='same')(rgb)\n",
    "rgb = MaxPooling3D(pool_size=(1,2,2))(rgb)\n",
    "\n",
    "rgb = Conv3D(\n",
    "    32, kernel_size=(1,3,3), strides=(1,1,1), kernel_initializer='he_normal', activation='relu', padding='same')(rgb)\n",
    "rgb = Conv3D(\n",
    "    32, kernel_size=(3,1,1), strides=(1,1,1), kernel_initializer='he_normal', activation='relu', padding='same')(rgb)\n",
    "rgb = MaxPooling3D(pool_size=(1,2,2))(rgb)\n",
    "\n",
    "rgb = Conv3D(\n",
    "    32, kernel_size=(1,3,3), strides=(1,1,1), kernel_initializer='he_normal', activation='relu', padding='same')(rgb)\n",
    "rgb = Conv3D(\n",
    "    32, kernel_size=(3,1,1), strides=(1,1,1), kernel_initializer='he_normal', activation='relu', padding='same')(rgb)\n",
    "rgb = MaxPooling3D(pool_size=(1,2,2))(rgb)\n",
    "##################################################### Optical Flow channel\n",
    "opt = Conv3D(\n",
    "    16, kernel_size=(1,3,3), strides=(1,1,1), kernel_initializer='he_normal', activation='relu', padding='same')(opt)\n",
    "opt = Conv3D(\n",
    "    16, kernel_size=(3,1,1), strides=(1,1,1), kernel_initializer='he_normal', activation='relu', padding='same')(opt)\n",
    "opt = MaxPooling3D(pool_size=(1,2,2))(opt)\n",
    "\n",
    "opt = Conv3D(\n",
    "    16, kernel_size=(1,3,3), strides=(1,1,1), kernel_initializer='he_normal', activation='relu', padding='same')(opt)\n",
    "opt = Conv3D(\n",
    "    16, kernel_size=(3,1,1), strides=(1,1,1), kernel_initializer='he_normal', activation='relu', padding='same')(opt)\n",
    "opt = MaxPooling3D(pool_size=(1,2,2))(opt)\n",
    "\n",
    "opt = Conv3D(\n",
    "    32, kernel_size=(1,3,3), strides=(1,1,1), kernel_initializer='he_normal', activation='relu', padding='same')(opt)\n",
    "opt = Conv3D(\n",
    "    32, kernel_size=(3,1,1), strides=(1,1,1), kernel_initializer='he_normal', activation='relu', padding='same')(opt)\n",
    "opt = MaxPooling3D(pool_size=(1,2,2))(opt)\n",
    "\n",
    "opt = Conv3D(\n",
    "    32, kernel_size=(1,3,3), strides=(1,1,1), kernel_initializer='he_normal', activation='sigmoid', padding='same')(opt)\n",
    "opt = Conv3D(\n",
    "    32, kernel_size=(3,1,1), strides=(1,1,1), kernel_initializer='he_normal', activation='sigmoid', padding='same')(opt)\n",
    "opt = MaxPooling3D(pool_size=(1,2,2))(opt)\n",
    "##################################################### Fusion and Pooling\n",
    "x = Multiply()([rgb,opt])\n",
    "x = MaxPooling3D(pool_size=(8,1,1))(x)\n",
    "\n",
    "##################################################### Merging Block\n",
    "x = Conv3D(\n",
    "    64, kernel_size=(1,3,3), strides=(1,1,1), kernel_initializer='he_normal', activation='relu', padding='same')(x)\n",
    "x = Conv3D(\n",
    "    64, kernel_size=(3,1,1), strides=(1,1,1), kernel_initializer='he_normal', activation='relu', padding='same')(x)\n",
    "x = MaxPooling3D(pool_size=(2,2,2))(x)\n",
    "\n",
    "x = Conv3D(\n",
    "    64, kernel_size=(1,3,3), strides=(1,1,1), kernel_initializer='he_normal', activation='relu', padding='same')(x)\n",
    "x = Conv3D(\n",
    "    64, kernel_size=(3,1,1), strides=(1,1,1), kernel_initializer='he_normal', activation='relu', padding='same')(x)\n",
    "x = MaxPooling3D(pool_size=(2,2,2))(x)\n",
    "\n",
    "x = Conv3D(\n",
    "    128, kernel_size=(1,3,3), strides=(1,1,1), kernel_initializer='he_normal', activation='relu', padding='same')(x)\n",
    "x = Conv3D(\n",
    "    128, kernel_size=(3,1,1), strides=(1,1,1), kernel_initializer='he_normal', activation='relu', padding='same')(x)\n",
    "x = MaxPooling3D(pool_size=(2,2,2))(x)\n",
    "\n",
    "##################################################### FC Layers\n",
    "# X = Flatten()(x)\n",
    "x = Dense(128,activation='relu')(x)\n",
    "x = Dropout(0.2)(x)\n",
    "x = Dense(32, activation='relu')(x)\n",
    "\n",
    "# Build the model\n",
    "pred = Dense(2, activation='sigmoid')(x)\n",
    "model = Model(inputs=inputs, outputs=pred)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "311981a9",
   "metadata": {
    "id": "311981a9"
   },
   "outputs": [],
   "source": [
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "\n",
    "# from tensorflow.python.keras.utils.multi_gpu_utils import multi_gpu_model\n",
    "# model = multi_gpu_model(model, gpus=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1e673c46",
   "metadata": {
    "id": "1e673c46"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import Adam, SGD\n",
    "\n",
    "sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model.compile(optimizer='sgd', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bd3beccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler\n",
    "\n",
    "def scheduler(epoch):\n",
    "    if epoch % 10 == 0 and epoch != 0:\n",
    "        lr = K.get_value(model.optimizer.lr)\n",
    "        K.set_value(model.optimizer.lr, lr * 0.7)\n",
    "    return K.get_value(model.optimizer.lr)\n",
    "\n",
    "reduce_lr = LearningRateScheduler(scheduler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "975b740b",
   "metadata": {
    "id": "975b740b"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint, CSVLogger,ReduceLROnPlateau\n",
    "from tensorflow import keras\n",
    "\n",
    "class MyCbk(keras.callbacks.Callback):\n",
    "\n",
    "    def __init__(self, model):\n",
    "         self.model_to_save = model\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        self.model_to_save.save('Logs/model_at_epoch_%d.h5' % (epoch+1))\n",
    "\n",
    "check_point = MyCbk(model)\n",
    "\n",
    "\n",
    "filename = 'Logs/ours_log.csv'\n",
    "csv_logger = CSVLogger(filename, separator=',', append=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3ac82fdb",
   "metadata": {
    "id": "3ac82fdb"
   },
   "outputs": [],
   "source": [
    "callbacks_list = [check_point, csv_logger, reduce_lr]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "246e3120",
   "metadata": {
    "id": "246e3120"
   },
   "outputs": [],
   "source": [
    "num_epochs  = 10\n",
    "num_workers = 16\n",
    "batch_size  = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3c757583",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3c757583",
    "outputId": "d271ee76-f244-4b22-e5ef-23f5f5bdd3a7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 22 files belonging to 2 classes.\n",
      "     Fight :  0\n",
      "  NonFight :  1\n",
      "Found 6 files belonging to 2 classes.\n",
      "     Fight :  0\n",
      "  NonFight :  1\n"
     ]
    }
   ],
   "source": [
    "dataset = 'data'\n",
    "\n",
    "# train_generator = DataGenerator(directory=r\"C:\\Users\\DELL\\Desktop\\Optical flow\\data1\\data\\train\", \n",
    "#                                 batch_size=batch_size, \n",
    "#                                 data_augmentation=True)\n",
    "\n",
    "# val_generator = DataGenerator(directory=r\"C:\\Users\\DELL\\Desktop\\Optical flow\\data1\\data\\val\",\n",
    "#                               batch_size=batch_size, \n",
    "#                               data_augmentation=False)\n",
    "\n",
    "dataset = 'data'\n",
    "train_generator = DataGenerator(directory= os.path.join('data1/{}/train'.format(dataset)), \n",
    "                                batch_size=batch_size, \n",
    "                                data_augmentation=True)\n",
    "\n",
    "val_generator = DataGenerator(directory='data1/{}/val'.format(dataset),\n",
    "                              batch_size=batch_size, \n",
    "                              data_augmentation=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "85cad92a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 381
    },
    "id": "85cad92a",
    "outputId": "566c98ef-a7b7-42bf-880d-3dadc5dc9bac"
   },
   "outputs": [],
   "source": [
    "# train_generator = np.asarray(train_generator)\n",
    "# train_generator = train_generator.resize(64,224,224,5)\n",
    "# print(train_generator[0])\n",
    "# tensorflow.squeeze(train_generator)\n",
    "# train_generator = tensorflow.convert_to_tensor(train_generator, dtype=tensorflow.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd0b8a18",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 236
    },
    "id": "fd0b8a18",
    "outputId": "996794f6-ddff-4614-8bd5-a5469e2a7070"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    }
   ],
   "source": [
    "hist = model.fit(\n",
    "    train_generator, \n",
    "    validation_data=val_generator,\n",
    "    callbacks=callbacks_list,\n",
    "    verbose=1, \n",
    "    epochs=num_epochs,\n",
    "    workers=num_workers,\n",
    "    max_queue_size=4,\n",
    "    steps_per_epoch=len(train_generator),\n",
    "    validation_steps=len(val_generator)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e5e51ec2",
   "metadata": {
    "id": "e5e51ec2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.4.0'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow\n",
    "tensorflow.keras.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c582d25f",
   "metadata": {
    "id": "c582d25f",
    "outputId": "d98a465a-fb5a-4ec6-cc89-dc5df73f808a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 317, 400, 3)\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "img = r\"E:\\5th sem\\image caption generator\\Images\\23445819_3a458716c1.jpg\"\n",
    "image = Image.open(img)\n",
    "image = np.expand_dims(image,axis=0)\n",
    "print(image.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a5ca224b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getOpticalFlow(video):\n",
    "    \"\"\"Calculate dense optical flow of input video\n",
    "    Args:\n",
    "        video: the input video with shape of [frames,height,width,channel]. dtype=np.array\n",
    "    Returns:\n",
    "        flows_x: the optical flow at x-axis, with the shape of [frames,height,width,channel]\n",
    "        flows_y: the optical flow at y-axis, with the shape of [frames,height,width,channel]\n",
    "    \"\"\"\n",
    "    # initialize the list of optical flows\n",
    "    gray_video = []\n",
    "    for i in range(len(video)):\n",
    "        img = cv2.cvtColor(video[i], cv2.COLOR_RGB2GRAY)\n",
    "        gray_video.append(np.reshape(img,(224,224,1)))\n",
    "\n",
    "    flows = []\n",
    "    for i in range(0,len(video)-1):\n",
    "        # calculate optical flow between each pair of frames\n",
    "        flow = cv2.calcOpticalFlowFarneback(gray_video[i], gray_video[i+1], None, 0.5, 3, 15, 3, 5, 1.2, cv2.OPTFLOW_FARNEBACK_GAUSSIAN)\n",
    "        # subtract the mean in order to eliminate the movement of camera\n",
    "        flow[..., 0] -= np.mean(flow[..., 0])\n",
    "        flow[..., 1] -= np.mean(flow[..., 1])\n",
    "        # normalize each component in optical flow\n",
    "        flow[..., 0] = cv2.normalize(flow[..., 0],None,0,255,cv2.NORM_MINMAX)\n",
    "        flow[..., 1] = cv2.normalize(flow[..., 1],None,0,255,cv2.NORM_MINMAX)\n",
    "        # Add into list \n",
    "        flows.append(flow)\n",
    "        \n",
    "    # Padding the last frame as empty array\n",
    "    flows.append(np.zeros((224,224,2)))\n",
    "      \n",
    "    return np.array(flows, dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d764367b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Video2Npy(file_path, resize=(224,224)):\n",
    "    \"\"\"Load video and tansfer it into .npy format\n",
    "    Args:\n",
    "        file_path: the path of video file\n",
    "        resize: the target resolution of output video\n",
    "    Returns:\n",
    "        frames: gray-scale video\n",
    "        flows: magnitude video of optical flows \n",
    "    \"\"\"\n",
    "    # Load video\n",
    "    cap = cv2.VideoCapture(file_path)\n",
    "    # Get number of frames\n",
    "    len_frames = int(cap.get(7))\n",
    "    # Extract frames from video\n",
    "    try:\n",
    "        frames = []\n",
    "        for i in range(len_frames-1):\n",
    "            _, frame = cap.read()\n",
    "            frame = cv2.resize(frame,resize, interpolation=cv2.INTER_AREA)\n",
    "            frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            frame = np.reshape(frame, (224,224,3))\n",
    "            frames.append(frame)   \n",
    "    except:\n",
    "        print(\"Error: \", file_path, len_frames,i)\n",
    "    finally:\n",
    "        frames = np.array(frames)\n",
    "        cap.release()\n",
    "            \n",
    "    # Get the optical flow of video\n",
    "    flows = getOpticalFlow(frames)\n",
    "    \n",
    "    result = np.zeros((len(flows),224,224,5))\n",
    "    result[...,:3] = frames\n",
    "    result[...,3:] = flows\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a30ccc1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = Video2Npy(file_path=r\"C:\\Users\\DELL\\Desktop\\Optical flow\\etyiEs3j8x8_4.avi\", resize=(224,224))\n",
    "data = np.uint8(data)   \n",
    "data = np.float32(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "aba352c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(149, 224, 224, 5)\n"
     ]
    }
   ],
   "source": [
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "42a10801",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-6-da5c0788e68e>:29: DeprecationWarning: listdir: path should be string, bytes, os.PathLike or None, not numpy.ndarray\n",
      "  self.dirs = sorted(os.listdir(self.directory))\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "listdir: embedded null character in path",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-45-9c016288f98e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDataGenerator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdata_augmentation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-6-da5c0788e68e>\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, directory, batch_size, shuffle, data_augmentation)\u001b[0m\n\u001b[0;32m     19\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata_aug\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata_augmentation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m         \u001b[1;31m# Load all the save_path of files, and create a dictionary that save the pair of \"data:label\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mX_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mY_dict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msearch_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m         \u001b[1;31m# Print basic statistics information\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprint_stats\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-6-da5c0788e68e>\u001b[0m in \u001b[0;36msearch_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     27\u001b[0m         \u001b[0mY_dict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m         \u001b[1;31m# list all kinds of sub-folders\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 29\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdirs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     30\u001b[0m         \u001b[0mone_hots\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_categorical\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdirs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfolder\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdirs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: listdir: embedded null character in path"
     ]
    }
   ],
   "source": [
    "data = DataGenerator(data,data_augmentation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "557e9e90",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Training.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
