{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9c89476c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def some_magic(string):\n",
    "    def warn(*args, **kwargs):\n",
    "        pass\n",
    "    import warnings\n",
    "    warnings.warn = warn\n",
    "\n",
    "    import matplotlib.pyplot as plt\n",
    "    from tqdm import tqdm\n",
    "    import numpy as np\n",
    "    import os\n",
    "    import time\n",
    "    from time import time\n",
    "    import cv2\n",
    "    import firebase_admin\n",
    "    from firebase_admin import credentials , firestore ,db\n",
    "\n",
    "#     cred = credentials.Certificate(\"data.json\")\n",
    "\n",
    "\n",
    "#     firebase_admin.initialize_app(cred,{\n",
    "#     'databaseURL': 'https://crimedetect-f51eb-default-rtdb.firebaseio.com/'\n",
    "#     })\n",
    "    import tensorflow\n",
    "    from tensorflow.keras.utils import Sequence\n",
    "    from tensorflow.keras import utils\n",
    "    from tensorflow.keras.utils import to_categorical\n",
    "    from tensorflow.python.keras.models  import Sequential, Input, Model\n",
    "    from tensorflow.keras.layers import Dense, Flatten, Conv3D, MaxPooling3D, Dropout, BatchNormalization, Activation, LeakyReLU, Add, Multiply\n",
    "    from tensorflow.keras.regularizers import l2\n",
    "    # from keras.layers.core import Lambda\n",
    "    from tensorflow.keras.layers import Lambda\n",
    "    # from keras.utils import np_utils\n",
    "\n",
    "    class DataGenerator(Sequence):\n",
    "        \"\"\"Data Generator inherited from keras.utils.Sequence\n",
    "        Args: \n",
    "            directory: the path of data set, and each sub-folder will be assigned to one class\n",
    "            batch_size: the number of data points in each batch\n",
    "            shuffle: whether to shuffle the data per epoch\n",
    "        Note:\n",
    "            If you want to load file with other data format, please fix the method of \"load_data\" as you want\n",
    "        \"\"\"\n",
    "        def __init__(self, directory, batch_size=1, shuffle=True, data_augmentation=True):\n",
    "            # Initialize the params\n",
    "            self.batch_size = batch_size\n",
    "            self.directory = directory\n",
    "            self.shuffle = shuffle\n",
    "            self.data_aug = data_augmentation\n",
    "            # Load all the save_path of files, and create a dictionary that save the pair of \"data:label\"\n",
    "            self.X_path, self.Y_dict = self.search_data() \n",
    "            # Print basic statistics information\n",
    "            self.print_stats()\n",
    "            return None\n",
    "        def search_data(self):\n",
    "            X_path = []\n",
    "            Y_dict = {}\n",
    "            # list all kinds of sub-folders\n",
    "            self.dirs = sorted(os.listdir(self.directory))\n",
    "            one_hots = utils.to_categorical(range(len(self.dirs)))\n",
    "            for i,folder in enumerate(self.dirs):\n",
    "                folder_path = os.path.join(self.directory,folder)\n",
    "                for file in os.listdir(folder_path):\n",
    "                    file_path = os.path.join(folder_path,file)\n",
    "                    # append the each file path, and keep its label  \n",
    "                    X_path.append(file_path)\n",
    "                    Y_dict[file_path] = one_hots[i]\n",
    "            return X_path, Y_dict\n",
    "    \n",
    "        def print_stats(self):\n",
    "            # calculate basic information\n",
    "            self.n_files = len(self.X_path)\n",
    "            self.n_classes = len(self.dirs)\n",
    "            self.indexes = np.arange(len(self.X_path))\n",
    "            np.random.shuffle(self.indexes)\n",
    "            # Output states\n",
    "            print(\"Found {} files belonging to {} classes.\".format(self.n_files,self.n_classes))\n",
    "            for i,label in enumerate(self.dirs):\n",
    "                print('%10s : '%(label),i)\n",
    "            return None\n",
    "        def __len__(self):\n",
    "            # calculate the iterations of each epoch\n",
    "            steps_per_epoch = np.ceil(len(self.X_path) / float(self.batch_size))\n",
    "            return int(steps_per_epoch)\n",
    "\n",
    "        def __getitem__(self, index):\n",
    "            \"\"\"Get the data of each batch\n",
    "            \"\"\"\n",
    "            # get the indexs of each batch\n",
    "            batch_indexs = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
    "            # using batch_indexs to get path of current batch\n",
    "            batch_path = [self.X_path[k] for k in batch_indexs]\n",
    "            # get batch data\n",
    "            batch_x, batch_y = self.data_generation(batch_path)\n",
    "            return batch_x, batch_y\n",
    "\n",
    "        def on_epoch_end(self):\n",
    "            # shuffle the data at each end of epoch\n",
    "            if self.shuffle == True:\n",
    "                np.random.shuffle(self.indexes)\n",
    "\n",
    "        def data_generation(self, batch_path):\n",
    "            # load data into memory, you can change the np.load to any method you want\n",
    "            batch_x = [self.load_data(x) for x in batch_path]\n",
    "            batch_y = [self.Y_dict[x] for x in batch_path]\n",
    "            # transfer the data format and take one-hot coding for labels\n",
    "            batch_x = np.array(batch_x)\n",
    "            batch_y = np.array(batch_y)\n",
    "            return batch_x, batch_y\n",
    "    \n",
    "        def normalize(self, data):\n",
    "            mean = np.mean(data)\n",
    "            std = np.std(data)\n",
    "            return (data-mean) / std\n",
    "    \n",
    "        def random_flip(self, video, prob):\n",
    "            s = np.random.rand()\n",
    "            if s < prob:\n",
    "                video = np.flip(m=video, axis=2)\n",
    "            return video    \n",
    "    \n",
    "        def uniform_sampling(self, video, target_frames=64):\n",
    "            # get total frames of input video and calculate sampling interval \n",
    "            len_frames = int(len(video))\n",
    "            interval = int(np.ceil(len_frames/target_frames))\n",
    "            # init empty list for sampled video and \n",
    "            sampled_video = []\n",
    "            for i in range(0,len_frames,interval):\n",
    "                sampled_video.append(video[i])     \n",
    "            # calculate numer of padded frames and fix it \n",
    "            num_pad = target_frames - len(sampled_video)\n",
    "            padding = []\n",
    "            if num_pad>0:\n",
    "                for i in range(-num_pad,0):\n",
    "                    try: \n",
    "                        padding.append(video[i])\n",
    "                    except:\n",
    "                        padding.append(video[0])\n",
    "                sampled_video += padding     \n",
    "            # get sampled video\n",
    "            return np.array(sampled_video, dtype=np.float32)\n",
    "    \n",
    "        def random_clip(self, video, target_frames=64):\n",
    "            start_point = np.random.randint(len(video)-target_frames)\n",
    "            return video[start_point:start_point+target_frames]\n",
    "    \n",
    "        def dynamic_crop(self, video):\n",
    "            # extract layer of optical flow from video\n",
    "            opt_flows = video[...,3]\n",
    "            # sum of optical flow magnitude of individual frame\n",
    "            magnitude = np.sum(opt_flows, axis=0)\n",
    "            # filter slight noise by threshold \n",
    "            thresh = np.mean(magnitude)\n",
    "            magnitude[magnitude<thresh] = 0\n",
    "            # calculate center of gravity of magnitude map and adding 0.001 to avoid empty value\n",
    "            x_pdf = np.sum(magnitude, axis=1) + 0.001\n",
    "            y_pdf = np.sum(magnitude, axis=0) + 0.001\n",
    "            # normalize PDF of x and y so that the sum of probs = 1\n",
    "            x_pdf /= np.sum(x_pdf)\n",
    "            y_pdf /= np.sum(y_pdf)\n",
    "            # randomly choose some candidates for x and y \n",
    "            x_points = np.random.choice(a=np.arange(224), size=10, replace=True, p=x_pdf)\n",
    "            y_points = np.random.choice(a=np.arange(224), size=10, replace=True, p=y_pdf)\n",
    "            # get the mean of x and y coordinates for better robustness\n",
    "            x = int(np.mean(x_points))\n",
    "            y = int(np.mean(y_points))\n",
    "            # avoid to beyond boundaries of array\n",
    "            x = max(56,min(x,167))\n",
    "            y = max(56,min(y,167))\n",
    "            # get cropped video \n",
    "            return video[:,x-56:x+56,y-56:y+56,:] \n",
    "\n",
    "        def color_jitter(self,video):\n",
    "            # range of s-component: 0-1\n",
    "            # range of v component: 0-255\n",
    "            s_jitter = np.random.uniform(-0.2,0.2)\n",
    "            v_jitter = np.random.uniform(-30,30)\n",
    "            for i in range(len(video)):\n",
    "                hsv = cv2.cvtColor(video[i], cv2.COLOR_RGB2HSV)\n",
    "                s = hsv[...,1] + s_jitter\n",
    "                v = hsv[...,2] + v_jitter\n",
    "                s[s<0] = 0\n",
    "                s[s>1] = 1\n",
    "                v[v<0] = 0\n",
    "                v[v>255] = 255\n",
    "                hsv[...,1] = s\n",
    "                hsv[...,2] = v\n",
    "                video[i] = cv2.cvtColor(hsv, cv2.COLOR_HSV2RGB)\n",
    "            return video\n",
    "\n",
    "        def load_data(self, path):\n",
    "            # load the processed .npy files which have 5 channels (1-3 for RGB, 4-5 for optical flows)\n",
    "            data = np.load(path, mmap_mode='r',allow_pickle=True)\n",
    "            data = np.float32(data)\n",
    "            # sampling 64 frames uniformly from the entire video\n",
    "            data = self.uniform_sampling(video=data, target_frames=64)\n",
    "            # whether to utilize the data augmentation\n",
    "            if  self.data_aug:\n",
    "                data[...,:3] = self.color_jitter(data[...,:3])\n",
    "                data = self.random_flip(data, prob=0.5)\n",
    "            # normalize rgb images and optical flows, respectively\n",
    "            data[...,:3] = self.normalize(data[...,:3])\n",
    "            data[...,3:] = self.normalize(data[...,3:])\n",
    "            return data\n",
    "\n",
    "    def Video2Npy(file_path, resize=(224,224)):\n",
    "        \"\"\"Load video and tansfer it into .npy format\n",
    "        Args:\n",
    "            file_path: the path of video file\n",
    "            resize: the target resolution of output video\n",
    "        Returns:\n",
    "            frames: gray-scale video\n",
    "            flows: magnitude video of optical flows \n",
    "        \"\"\"\n",
    "        # Load video\n",
    "        cap = cv2.VideoCapture(file_path)\n",
    "        # Get number of frames\n",
    "        len_frames = int(cap.get(7))\n",
    "        # Extract frames from video\n",
    "        try:\n",
    "            frames = []\n",
    "            for i in range(len_frames-1):\n",
    "                _, frame = cap.read()\n",
    "                frame = cv2.resize(frame,resize, interpolation=cv2.INTER_AREA)\n",
    "                frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "                frame = np.reshape(frame, (224,224,3))\n",
    "                frames.append(frame)   \n",
    "        except:\n",
    "            print(\"Error: \", file_path, len_frames,i)\n",
    "        finally:\n",
    "            frames = np.array(frames)\n",
    "            cap.release()\n",
    "\n",
    "        # Get the optical flow of video\n",
    "        flows = getOpticalFlow(frames)\n",
    "\n",
    "        result = np.zeros((len(flows),224,224,5))\n",
    "        result[...,:3] = frames\n",
    "        result[...,3:] = flows\n",
    "\n",
    "        return result\n",
    "    \n",
    "    def getOpticalFlow(video):\n",
    "        \"\"\"Calculate dense optical flow of input video\n",
    "        Args:\n",
    "            video: the input video with shape of [frames,height,width,channel]. dtype=np.array\n",
    "        Returns:\n",
    "            flows_x: the optical flow at x-axis, with the shape of [frames,height,width,channel]\n",
    "            flows_y: the optical flow at y-axis, with the shape of [frames,height,width,channel]\n",
    "        \"\"\"\n",
    "        # initialize the list of optical flows\n",
    "        gray_video = []\n",
    "        for i in range(len(video)):\n",
    "            img = cv2.cvtColor(video[i], cv2.COLOR_RGB2GRAY)\n",
    "            gray_video.append(np.reshape(img,(224,224,1)))\n",
    "\n",
    "        flows = []\n",
    "        for i in range(0,len(video)-1):\n",
    "            # calculate optical flow between each pair of frames\n",
    "            flow = cv2.calcOpticalFlowFarneback(gray_video[i], gray_video[i+1], None, 0.5, 3, 15, 3, 5, 1.2, cv2.OPTFLOW_FARNEBACK_GAUSSIAN)\n",
    "            # subtract the mean in order to eliminate the movement of camera\n",
    "            flow[..., 0] -= np.mean(flow[..., 0])\n",
    "            flow[..., 1] -= np.mean(flow[..., 1])\n",
    "            # normalize each component in optical flow\n",
    "            flow[..., 0] = cv2.normalize(flow[..., 0],None,0,255,cv2.NORM_MINMAX)\n",
    "            flow[..., 1] = cv2.normalize(flow[..., 1],None,0,255,cv2.NORM_MINMAX)\n",
    "            # Add into list \n",
    "            flows.append(flow)\n",
    "\n",
    "        # Padding the last frame as empty array\n",
    "        flows.append(np.zeros((224,224,2)))\n",
    "\n",
    "        return np.array(flows, dtype=np.float32)\n",
    "\n",
    "\n",
    "    def Save2Npy(file_dir, save_dir):\n",
    "        \"\"\"Transfer all the videos and save them into specified directory\n",
    "        Args:\n",
    "            file_dir: source folder of target videos\n",
    "            save_dir: destination folder of output .npy files\n",
    "        \"\"\"\n",
    "        if not os.path.exists(save_dir):\n",
    "            os.makedirs(save_dir)\n",
    "        # List the files\n",
    "        videos = os.listdir(file_dir)\n",
    "        for v in tqdm(videos):\n",
    "            # Split video name\n",
    "            video_name = v.split('.')[0]\n",
    "            # Get src \n",
    "            video_path = os.path.join(file_dir, v)\n",
    "            # Get dest \n",
    "            save_path = os.path.join(save_dir, video_name+'.npy') \n",
    "            # Load and preprocess video\n",
    "            data = Video2Npy(file_path=video_path, resize=(224,224))\n",
    "            data = np.uint8(data)\n",
    "            # Save as .npy file\n",
    "            np.save(save_path, data)\n",
    "\n",
    "        return None\n",
    "        \n",
    "        \n",
    "    from os import listdir\n",
    "    from os.path import isfile, join\n",
    "    if string==\"web\":\n",
    "        import numpy as np\n",
    "        import cv2\n",
    "        import time\n",
    "\n",
    "        # The duration in seconds of the video captured\n",
    "        for i in range(2):\n",
    "            capture_duration = 5\n",
    "\n",
    "            cap = cv2.VideoCapture(0)\n",
    "\n",
    "            fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "            out = cv2.VideoWriter(r'E:\\go_ai\\last-crime\\ourliv\\12-0362_77-4886'+str(i)+'.avi',fourcc, 20.0, (640,480))\n",
    "\n",
    "            start_time = time.time()\n",
    "            while( int(time.time() - start_time) < capture_duration ):\n",
    "                ret, frame = cap.read()\n",
    "                if ret==True:\n",
    "                    frame = cv2.flip(frame,0)\n",
    "                    out.write(frame)\n",
    "                    cv2.imshow('frame',frame)\n",
    "                else:\n",
    "                    break\n",
    "\n",
    "            cap.release()\n",
    "            out.release()\n",
    "            cv2.destroyAllWindows()\n",
    "            \n",
    "        source_path = r'E:\\go_ai\\last-crime\\ourliv'\n",
    "        target_path = r'E:\\go_ai\\last-crime\\data\\our\\vid'\n",
    "        Save2Npy(source_path, target_path)\n",
    "        onlyfiles = [f for f in listdir(r'E:\\go_ai\\last-crime\\data\\our\\vid') if isfile(join(r'E:\\go_ai\\last-crime\\data\\our\\vid', f))]\n",
    "        list = os.listdir(r'E:\\go_ai\\last-crime\\data\\our\\vid') # dir is your directory path\n",
    "        number_files = len(list)\n",
    "        print(number_files)\n",
    "        val_generator = DataGenerator(directory=r'E:\\go_ai\\last-crime\\data\\our',\n",
    "                              batch_size=1, \n",
    "                              data_augmentation=False)\n",
    "    if string==\"local\":\n",
    "        source_path = r'E:\\go_ai\\last-crime\\video'\n",
    "        target_path = r'E:\\go_ai\\last-crime\\data\\sam\\vi'\n",
    "        Save2Npy(source_path, target_path)\n",
    "        onlyfiles = [f for f in listdir(r'E:\\go_ai\\last-crime\\data\\sam\\vi') if isfile(join(r'E:\\go_ai\\last-crime\\data\\sam\\vi', f))]\n",
    "        list = os.listdir(r'E:\\go_ai\\last-crime\\data\\sam\\vi') # dir is your directory path\n",
    "        number_files = len(list)\n",
    "        print(number_files)\n",
    "        val_generator = DataGenerator(directory=r'E:\\go_ai\\last-crime\\data\\sam',\n",
    "                              batch_size=1, \n",
    "                              data_augmentation=False)\n",
    "        \n",
    "    def addData(lat_lang,time):\n",
    "        ref = db.reference(\"/\")\n",
    "        res=ref.get(\"/\")\n",
    "        print(res[0])\n",
    "        res[0][lat_lang]=time\n",
    "        res=ref.set(res[0])\n",
    "        \n",
    "    from pickle import load\n",
    "    from tensorflow.keras.models import load_model\n",
    "    hist = load_model('keras_model.h5')\n",
    "        \n",
    "    import datetime\n",
    "    pred = hist.predict(val_generator)\n",
    "    \n",
    "    print(pred)\n",
    "    s=[]\n",
    "    for i in range(number_files):\n",
    "        if pred[i][0] > 0.7:\n",
    "            e = datetime.datetime.now()\n",
    "            date_time = e.strftime(\"%m/%d/%Y, %H:%M:%S\")\n",
    "            print(\"date and time:\", date_time)\n",
    "            if(string==\"web\"):\n",
    "                name = onlyfiles[i].replace(\".npy\",\"\")\n",
    "            else:\n",
    "                name = onlyfiles[i].replace(\".npy\",\"\")\n",
    "            s.append(name+\" crime has been detected at \"+str(e))\n",
    "            print(s)\n",
    "#             addData(name,date_time)\n",
    "    return s\n",
    "            \n",
    "#     import os\n",
    "#     if string==\"web\":\n",
    "#         dir = 'E:\\go_ai\\last-crime\\data\\our\\vid'\n",
    "#     else:\n",
    "#         dir = 'E:\\go_ai\\last-crime\\data\\sam\\vi'\n",
    "#     for f in os.listdir(dir):\n",
    "#         os.remove(os.path.join(dir, f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2379f24b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:54<00:00,  6.86s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n",
      "Found 8 files belonging to 1 classes.\n",
      "        vi :  0\n",
      "8/8 [==============================] - 26s 3s/step\n",
      "[[0.77555305 0.22444694]\n",
      " [0.8940509  0.10594905]\n",
      " [0.8520385  0.14796145]\n",
      " [0.8709945  0.1290055 ]\n",
      " [0.05960685 0.94039315]\n",
      " [0.16322285 0.83677715]\n",
      " [0.8497123  0.1502877 ]\n",
      " [0.82839036 0.17160961]]\n",
      "date and time: 07/06/2022, 15:52:59\n",
      "['12-8413_77-6618 crime has been detected at 2022-07-06 15:52:59.189796']\n",
      "date and time: 07/06/2022, 15:52:59\n",
      "['12-8413_77-6618 crime has been detected at 2022-07-06 15:52:59.189796', '12-8831_77-6164 crime has been detected at 2022-07-06 15:52:59.191795']\n",
      "date and time: 07/06/2022, 15:52:59\n",
      "['12-8413_77-6618 crime has been detected at 2022-07-06 15:52:59.189796', '12-8831_77-6164 crime has been detected at 2022-07-06 15:52:59.191795', '12-8979_77-5843 crime has been detected at 2022-07-06 15:52:59.193793']\n",
      "date and time: 07/06/2022, 15:52:59\n",
      "['12-8413_77-6618 crime has been detected at 2022-07-06 15:52:59.189796', '12-8831_77-6164 crime has been detected at 2022-07-06 15:52:59.191795', '12-8979_77-5843 crime has been detected at 2022-07-06 15:52:59.193793', '12-9117_77-5369 crime has been detected at 2022-07-06 15:52:59.195795']\n",
      "date and time: 07/06/2022, 15:52:59\n",
      "['12-8413_77-6618 crime has been detected at 2022-07-06 15:52:59.189796', '12-8831_77-6164 crime has been detected at 2022-07-06 15:52:59.191795', '12-8979_77-5843 crime has been detected at 2022-07-06 15:52:59.193793', '12-9117_77-5369 crime has been detected at 2022-07-06 15:52:59.195795', '12-9866_77-6513 crime has been detected at 2022-07-06 15:52:59.198793']\n",
      "date and time: 07/06/2022, 15:52:59\n",
      "['12-8413_77-6618 crime has been detected at 2022-07-06 15:52:59.189796', '12-8831_77-6164 crime has been detected at 2022-07-06 15:52:59.191795', '12-8979_77-5843 crime has been detected at 2022-07-06 15:52:59.193793', '12-9117_77-5369 crime has been detected at 2022-07-06 15:52:59.195795', '12-9866_77-6513 crime has been detected at 2022-07-06 15:52:59.198793', '13-0334_77-4900 crime has been detected at 2022-07-06 15:52:59.198793']\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    some_magic(\"local\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f61b064",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8bbbd0b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
